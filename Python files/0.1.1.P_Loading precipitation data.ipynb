{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(data, sort, create=False):\n",
    "    unique_station = data.STATION.unique()\n",
    "    unique_lat = np.zeros(len(unique_station))\n",
    "    unique_lon = np.zeros(len(unique_station))\n",
    "    \n",
    "    for index, station in enumerate(unique_station):\n",
    "        unique_lat[index] = data[data.STATION == station].LATITUDE[0]\n",
    "        unique_lon[index] = data[data.STATION == station].LONGITUDE[0]\n",
    "        \n",
    "    \n",
    "    locations = pd.DataFrame([unique_station, unique_lat, unique_lon]).T\n",
    "\n",
    "    locations = locations.rename({0:'station ID', 1:'lat', 2:'lon'}, axis='columns')\n",
    "    \n",
    "    if create == True:\n",
    "        locations.to_csv(f'{data_folder}\\\\locations_{sort}.csv')\n",
    "        return locations\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_station(data, locations, sort, create=False):\n",
    "    locations = np.array(locations)\n",
    "    #unique_station = data.STATION.unique()\n",
    "    #create a data frame dictionary to store your data frames\n",
    "    DataFrameDict = {x : pd.DataFrame() for x in locations}\n",
    "\n",
    "    for key in DataFrameDict.keys():\n",
    "        DataFrameDict[key] = data[:][data.STATION == key]\n",
    "        if create == True:\n",
    "            DataFrameDict[key].to_csv(f'{data_folder}\\\\data per station\\\\data_{key}_{sort}.csv')\n",
    "    return DataFrameDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dataframe(dict_data, sort):\n",
    "    df_list = []\n",
    "    for name in dict_data.keys():\n",
    "        DF = pd.read_csv(f'{data_folder}\\\\data per station\\\\data_{name}_{sort}.csv', index_col='DATE', parse_dates=True)\n",
    "        df_list.append(DF)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "All data is downloaded from:  https://www.ncei.noaa.gov/cdo-web/ and is prepared in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "home_path = os.path.dirname(path)\n",
    "data_folder = f'{home_path}\\\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\3285895.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\3286005.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\precipitation_troylockdam.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\Q_ids_with_begin-end-date.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f\"{data_folder}\\\\*.csv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_P = pd.read_csv(files[1], index_col='DATE', usecols=['DATE', 'PRCP', 'STATION', 'LATITUDE', 'LONGITUDE'],  delimiter=',', parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\P\\\\average_P.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\P\\\\locations_evap.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\P\\\\locations_P.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\P\\\\locations_prcp.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\P\\\\locations_P_in_basin.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\P\\\\location_northern_basin.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f\"{data_folder}\\\\P\\\\*.csv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_basins = pd.read_csv(files[-1], usecols=['station ID']).values.tolist()\n",
    "locations_basins = np.stack( locations_basins, axis=1 )[0]\n",
    "\n",
    "dict_stations_P = split_df_station(data_P, locations_basins, 'prcp') #, create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_prcp = list_dataframe(dict_stations_P, 'prcp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_data(df_lst, column):\n",
    "    \n",
    "    df_lst_data = []\n",
    "    \n",
    "    for i in range(len(df_lst)):\n",
    "        df_data = df_lst[i][column]\n",
    "        df_data.to_frame()\n",
    "        \n",
    "        df_lst_data.append(df_data)\n",
    "    \n",
    "    df = pd.concat(df_lst_data, axis=1)\n",
    "    df_avg = df.mean(axis=1).to_frame()\n",
    "    return df_avg\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_prcp = average_data(df_list_prcp, 'PRCP')\n",
    "average_prcp.columns = ['P']\n",
    "average_prcp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_prcp.to_parquet(f\"{data_folder}\\\\P\\\\average_P.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "average_prcp.loc['1900'::].plot(ax=ax)\n",
    "ax.set_ylabel('Precipitation [mm]')\n",
    "ax.set_title('Average Precipitation Stations in Basins');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4] \n",
    "b = [2,3,4,5]\n",
    "c=[]\n",
    "c+= a\n",
    "c+=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\T\\\\3292614.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\T\\\\locations_temp.csv',\n",
       " 'C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\T\\\\locations_temperature_in_nothern_basin.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "home_path = os.path.dirname(path)\n",
    "data_folder = f'{home_path}\\\\Data\\\\T'\n",
    "files = glob.glob(f\"{data_folder}\\\\*.csv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T = pd.read_csv(files[0],  delimiter=',', index_col=['DATE'], parse_dates=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = data_T.STATION.unique()\n",
    "dict_stations_T = split_df_station(data_T, locations, 'temp')#, create=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_temp = list_dataframe(dict_stations_T, 'temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_list_temp)):\n",
    "    df_list_temp[i].to_parquet(f'{data_folder}\\\\data\\\\data_{i}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_temp = get_location(data_T, 'temp')#, create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_temp_north = pd.read_csv(files[2], usecols=['station ID']).values.tolist()\n",
    "locations_temp_north = np.stack(locations_temp_north, axis=1 )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, name in enumerate(locations_temp_north):\n",
    "    file = glob.glob(f\"{data_folder}\\\\data per station\\\\*{name}*.csv\")\n",
    "    df = pd.read_csv(file[0])\n",
    "    df.to_parquet(f'{data_folder}\\\\data parquet basin\\\\temp_{name}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\anne-\\\\OneDrive - Delft University of Technology\\\\Documenten\\\\Environmental Engineering MSc\\\\ENVM1502-Catchment-model\\\\Data\\\\T\\\\data per station\\\\data_USC00305769_temp.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
